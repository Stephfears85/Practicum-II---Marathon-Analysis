{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a7d2bf6a-ad2d-49d7-9b7f-396a5b79816e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\steph\\anaconda3\\lib\\site-packages (2.32.3)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\steph\\anaconda3\\lib\\site-packages (4.12.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\steph\\anaconda3\\lib\\site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\steph\\anaconda3\\lib\\site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\steph\\anaconda3\\lib\\site-packages (from requests) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\steph\\anaconda3\\lib\\site-packages (from requests) (2024.12.14)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\steph\\anaconda3\\lib\\site-packages (from beautifulsoup4) (2.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install requests beautifulsoup4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5b28b0e3-5992-4351-97de-eca334ed8c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2b6454bc-1f0b-4cba-8615-965b4e6940ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to fetch runner data with split times...\n",
      "Fetching results from index: 0\n",
      "Fetched 50 runners on this page.\n",
      "Fetching results from index: 50\n",
      "Fetched 50 runners on this page.\n",
      "Fetching results from index: 100\n",
      "Fetched 50 runners on this page.\n",
      "Fetching results from index: 150\n",
      "Fetched 50 runners on this page.\n",
      "Fetching results from index: 200\n",
      "Fetched 50 runners on this page.\n",
      "Fetching results from index: 250\n",
      "Fetched 4 runners on this page.\n",
      "Fetching results from index: 300\n",
      "Unexpected JSON structure for runner results.\n",
      "\n",
      "Successfully collected data for 254 runners.\n",
      "\n",
      "Example of the first runner's data:\n",
      "{\n",
      "    \"name\": \"Calvin Lehn\",\n",
      "    \"bib\": \"263\",\n",
      "    \"gender\": \"M\",\n",
      "    \"overall_time_ms\": 9522000,\n",
      "    \"overall_time_readable\": \"2:38:42\",\n",
      "    \"splits\": {\n",
      "        \"Full Course\": \"2:38:41\",\n",
      "        \"13.1 Miles\": \"1:17:46\"\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "event_id = \"1074826\"\n",
    "race_id = \"2449286\"\n",
    "base_results_url = f\"https://reignite-api.athlinks.com/event/{event_id}/race/{race_id}/results\"\n",
    "base_runner_url = f\"https://reignite-api.athlinks.com/event/{event_id}/race/{race_id}/bib/{{bib_number}}/result\"\n",
    "all_runners_data = []\n",
    "from_param = 0\n",
    "limit = 50\n",
    "\n",
    "print(\"Starting to fetch runner data with split times...\")\n",
    "\n",
    "while True:\n",
    "    params = {\"from\": from_param, \"limit\": limit}\n",
    "    print(f\"Fetching results from index: {from_param}\")\n",
    "    try:\n",
    "        response = requests.get(base_results_url, params=params)\n",
    "        response.raise_for_status()\n",
    "        try:\n",
    "            data = response.json()\n",
    "            if \"intervals\" in data and isinstance(data[\"intervals\"], list) and len(data[\"intervals\"]) > 0 and \"results\" in data[\"intervals\"][0] and isinstance(data[\"intervals\"][0][\"results\"], list):\n",
    "                runners = data[\"intervals\"][0][\"results\"]\n",
    "                print(f\"Fetched {len(runners)} runners on this page.\")\n",
    "\n",
    "                for runner in runners:\n",
    "                    runner_info = {\n",
    "                        \"name\": runner.get(\"displayName\"),\n",
    "                        \"bib\": runner.get(\"bib\"),\n",
    "                        \"gender\": runner.get(\"gender\"),\n",
    "                        \"overall_time_ms\": runner.get(\"gunTimeInMillis\"), # Keep milliseconds for now\n",
    "                        \"overall_time_readable\": str(datetime.timedelta(milliseconds=runner.get(\"gunTimeInMillis\"))),\n",
    "                        \"splits\": {}\n",
    "                    }\n",
    "\n",
    "                    bib_number = runner.get(\"bib\")\n",
    "                    if bib_number:\n",
    "                        runner_detail_url = base_runner_url.format(bib_number=bib_number)\n",
    "                        try:\n",
    "                            detail_response = requests.get(runner_detail_url)\n",
    "                            detail_response.raise_for_status()\n",
    "                            detail_data = detail_response.json()\n",
    "                            if \"intervals\" in detail_data and isinstance(detail_data[\"intervals\"], list):\n",
    "                                for interval in detail_data[\"intervals\"]:\n",
    "                                    interval_name = interval.get(\"name\")\n",
    "                                    chip_time_millis = interval.get(\"chipTimeInMillis\")\n",
    "                                    if interval_name and chip_time_millis is not None:\n",
    "                                        time_obj = datetime.timedelta(milliseconds=chip_time_millis)\n",
    "                                        readable_time = str(time_obj)\n",
    "                                        runner_info[\"splits\"][interval_name] = readable_time\n",
    "\n",
    "                        except requests.exceptions.RequestException as e:\n",
    "                            print(f\"Error fetching details for bib {bib_number}: {e}\")\n",
    "                        except json.JSONDecodeError:\n",
    "                            print(f\"Error decoding JSON for bib {bib_number}\")\n",
    "\n",
    "                    all_runners_data.append(runner_info)\n",
    "\n",
    "                from_param += limit\n",
    "                time.sleep(1)\n",
    "\n",
    "            else:\n",
    "                print(\"Unexpected JSON structure for runner results.\")\n",
    "                break\n",
    "\n",
    "        except json.JSONDecodeError:\n",
    "            print(\"Error decoding JSON response:\")\n",
    "            print(response.text)\n",
    "            break\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching page {from_param // limit + 1}: {e}\")\n",
    "        break\n",
    "\n",
    "print(f\"\\nSuccessfully collected data for {len(all_runners_data)} runners.\")\n",
    "# You can now process the 'all_runners_data' list.\n",
    "# For example, print the first runner's data with splits:\n",
    "if all_runners_data:\n",
    "    print(\"\\nExample of the first runner's data:\")\n",
    "    print(json.dumps(all_runners_data[0], indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1bfa9c12-ede2-408e-a799-be7ba6fd8add",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully written to race_results2.csv using pandas (without re-fetching).\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#'all_runners_data' list is still populated\n",
    "\n",
    "csv_file_path = 'race_results2.csv'\n",
    "\n",
    "if 'all_runners_data' in locals() and all_runners_data:\n",
    "    df = pd.DataFrame(all_runners_data)\n",
    "\n",
    "    # Separate the 'splits' dictionary into individual columns\n",
    "    splits_df = pd.json_normalize(df['splits'])\n",
    "\n",
    "    # Concatenate the main DataFrame with the splits DataFrame\n",
    "    df = pd.concat([df.drop('splits', axis=1), splits_df], axis=1)\n",
    "\n",
    "    # Save the DataFrame to a CSV file\n",
    "    df.to_csv(csv_file_path, index=False, encoding='utf-8')\n",
    "\n",
    "    print(f\"Data successfully written to {csv_file_path} using pandas (without re-fetching).\")\n",
    "else:\n",
    "    print(\"Error: The 'all_runners_data' list does not exist or is empty. Please run the data fetching part first.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
